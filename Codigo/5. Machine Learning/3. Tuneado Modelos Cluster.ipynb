{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3030d3",
   "metadata": {},
   "source": [
    "## 3. Tuneado Modelos Clúster\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Proceso para la selección de los mejores parámetros de cada uno de los algoritmos a traves de la metodología GridSearchCV.\n",
    "\n",
    "### Descripción General de notebook\n",
    "\n",
    "    1. Carga de datos base        \n",
    "    2. Definición los parámetros a incluir en la grilla de cada uno de los algoritmos\n",
    "    3. Determinar los mejores parámetros para cada uno de los algoritmos de cada clúster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6311ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import MultiIndex, Int16Dtype\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer, RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, LinearRegression, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge,LinearRegression, LogisticRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Warnings configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3e223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../7. Prediccion/Funciones_Prepara_Prediccion.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bcef1",
   "metadata": {},
   "source": [
    "### Preparación datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78bedd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 176477 entries, 0 to 176476\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   ESTACION                  176477 non-null  int64  \n",
      " 1   DEMANDA                   176477 non-null  float64\n",
      " 2   MES_sen                   176477 non-null  float64\n",
      " 3   MES_cos                   176477 non-null  float64\n",
      " 4   TEMP_MAX                  176477 non-null  float64\n",
      " 5   TEMP_MIN                  176477 non-null  float64\n",
      " 6   HUMEDAD                   176477 non-null  float64\n",
      " 7   VIENTO                    176477 non-null  float64\n",
      " 8   PRESION                   176477 non-null  float64\n",
      " 9   PRECIPITACION_1h          176477 non-null  float64\n",
      " 10  PRECIPITACION_3h          176477 non-null  float64\n",
      " 11  Es_Festivo_1              176477 non-null  uint8  \n",
      " 12  Es_FinSemana_1            176477 non-null  uint8  \n",
      " 13  TEMPORADA_OTONO           176477 non-null  uint8  \n",
      " 14  TEMPORADA_PRIMAVERA       176477 non-null  uint8  \n",
      " 15  TEMPORADA_VERANO          176477 non-null  uint8  \n",
      " 16  DIA_SEMANA_2              176477 non-null  uint8  \n",
      " 17  DIA_SEMANA_3              176477 non-null  uint8  \n",
      " 18  DIA_SEMANA_4              176477 non-null  uint8  \n",
      " 19  DIA_SEMANA_5              176477 non-null  uint8  \n",
      " 20  DIA_SEMANA_6              176477 non-null  uint8  \n",
      " 21  DIA_SEMANA_7              176477 non-null  uint8  \n",
      " 22  DESC_TIEMPO_Clouds        176477 non-null  uint8  \n",
      " 23  DESC_TIEMPO_Drizzle       176477 non-null  uint8  \n",
      " 24  DESC_TIEMPO_Fog           176477 non-null  uint8  \n",
      " 25  DESC_TIEMPO_Mist          176477 non-null  uint8  \n",
      " 26  DESC_TIEMPO_Rain          176477 non-null  uint8  \n",
      " 27  DESC_TIEMPO_Snow          176477 non-null  uint8  \n",
      " 28  DESC_TIEMPO_Thunderstorm  176477 non-null  uint8  \n",
      "dtypes: float64(10), int64(1), uint8(18)\n",
      "memory usage: 17.8 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# bicimad_def = _dataBaseOriginal(\"../../Data/DataFrame_Final_Cierre_Cluster.csv\")\n",
    "bicimad = _dataBaseOriginal(\"../../Data/DataFrame_Final_Cierre_Cluster_2017_2019.csv\")\n",
    "bicimad.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d209d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv(\"../../Data/DataFrame_Final_Cierre_Cluster_2017_2019.csv\", parse_dates=['FECHA'])\n",
    "\n",
    "cluster0_estaciones = datos[datos['CLUSTER_soloDemanda']==0].ESTACION.unique()\n",
    "cluster1_estaciones = datos[datos['CLUSTER_soloDemanda']==1].ESTACION.unique()\n",
    "cluster2_estaciones = datos[datos['CLUSTER_soloDemanda']==2].ESTACION.unique()\n",
    "cluster3_estaciones = datos[datos['CLUSTER_soloDemanda']==3].ESTACION.unique()\n",
    "cluster4_estaciones = datos[datos['CLUSTER_soloDemanda']==4].ESTACION.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508d661",
   "metadata": {},
   "source": [
    "Se definen los algoritmos a utilizar en cada uno de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440b346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99\n",
    "\n",
    "models = list()\n",
    "models.append(('RFR', RandomForestRegressor(random_state=seed)))\n",
    "models.append(('GBR', GradientBoostingRegressor(random_state=seed)))\n",
    "models.append(('LGBMR', LGBMRegressor(random_state=seed)))\n",
    "models.append(('XGBR', XGBRegressor(random_state=seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f374d",
   "metadata": {},
   "source": [
    "Se definen los parámetros para cada uno de los algoritmos a incluir en el GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e33fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_RF = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3,5,7],\n",
    "    'min_samples_leaf': [1,2,3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100,500,1000]\n",
    "}\n",
    "\n",
    "param_grid_GB = {\n",
    "    'learning_rate': [0.01,0.02,0.04, 0.1],\n",
    "    'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "    'n_estimators' : [100,500,1000, 1500],\n",
    "    'max_depth'    : [80, 90, 100,110]\n",
    "}\n",
    "\n",
    "param_grid_LGBM = {\n",
    "    'learning_rate': [0.005, 0.01, 0.1],\n",
    "    'n_estimators': [10,100,500, 1000],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'max_depth':[25, 50, 100, 500]\n",
    "}\n",
    "\n",
    "param_grid_XGB = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'n_estimators':[100,700,1000],\n",
    "    'max_depth': [3,5,8],\n",
    "    'min_child_weight': [1,2,3,4],\n",
    "    'gamma':[0, 0.1, 0.2],\n",
    "    'reg_alpha': [0.1,1,200],#L1\n",
    "    'reg_lambda':[1,200,500],#L2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed57587b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  9,  43,  57,  58,  64,  90, 129, 135, 160, 163, 168, 149, 175],\n",
       "       dtype=int64),\n",
       " array([  3,   8,  17,  30,  42,  48,  53,  55,  71,  75,  76,  86,  95,\n",
       "        103, 113, 115, 118, 131, 136, 145, 157,  65,  78, 155,  91, 156,\n",
       "         99, 139], dtype=int64),\n",
       " array([ 15,  23,  24,  29,  35,  37,  40,  97,  98, 100, 107, 109, 111,\n",
       "        120, 122, 147, 158, 159, 174,  11,  28,  32,  36,  88, 117, 119,\n",
       "        127, 137, 140, 143, 144, 152, 165,  34,  39,  60, 104, 112, 138,\n",
       "        141, 151,  85, 173,  61, 150,  72, 101,  87, 105, 146], dtype=int64),\n",
       " array([  1,   6,  13,  19,  26,  38,  41,  45,  46,  49,  52,  59,  62,\n",
       "         74,  84, 108, 114, 128, 132, 161, 164, 166, 169, 170,  31,  56,\n",
       "         83, 133, 162,  79], dtype=int64),\n",
       " array([  2,   4,   5,   7,  10,  12,  16,  18,  21,  25,  27,  33,  44,\n",
       "         47,  50,  51,  54,  63,  66,  67,  77,  81,  93, 102, 110, 116,\n",
       "        121, 123, 124, 125, 126, 134, 148, 153, 171,  20,  73,  80,  92,\n",
       "        130, 142, 154, 167,  96, 172, 106,  82,  94,  14,  69,  89],\n",
       "       dtype=int64)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterTotal = [cluster0_estaciones,\n",
    "                cluster1_estaciones,\n",
    "                cluster2_estaciones,\n",
    "                cluster3_estaciones,\n",
    "                cluster4_estaciones]\n",
    "clusterTotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a7cb4e",
   "metadata": {},
   "source": [
    "## Tuneado modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860598d",
   "metadata": {},
   "source": [
    "Para el tuneado de cada uno de los modelos se ha realizado lo siguiente:\n",
    "\n",
    " - Se selecciona los datos de cada uno de los clúster\n",
    " - Creación de un modelo base para cada uno de los algoritmos\n",
    " - Realizar el tuneado de cada modelo a través de la función grid_search\n",
    " - Determinación del mejor modelo a través del grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "addbd1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      "Estaciones: 13\n",
      "Columnas: 29\n",
      "Fitting 2 folds for each of 720 candidates, totalling 1440 fits\n",
      "{'bootstrap': True, 'max_depth': 80, 'max_features': 7, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 1000}\n",
      "\n",
      "Cluster: 1\n",
      "Estaciones: 28\n",
      "Columnas: 29\n",
      "Fitting 2 folds for each of 720 candidates, totalling 1440 fits\n",
      "{'bootstrap': True, 'max_depth': 80, 'max_features': 7, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 1000}\n",
      "\n",
      "Cluster: 2\n",
      "Estaciones: 50\n",
      "Columnas: 29\n",
      "Fitting 2 folds for each of 720 candidates, totalling 1440 fits\n",
      "{'bootstrap': True, 'max_depth': 80, 'max_features': 7, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 1000}\n",
      "\n",
      "Cluster: 3\n",
      "Estaciones: 30\n",
      "Columnas: 29\n",
      "Fitting 2 folds for each of 720 candidates, totalling 1440 fits\n",
      "{'bootstrap': True, 'max_depth': 80, 'max_features': 7, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 1000}\n",
      "\n",
      "Cluster: 4\n",
      "Estaciones: 51\n",
      "Columnas: 29\n",
      "Fitting 2 folds for each of 720 candidates, totalling 1440 fits\n",
      "{'bootstrap': True, 'max_depth': 80, 'max_features': 7, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 1000}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paramRF = []\n",
    "iPos = 0\n",
    "for cluster in clusterTotal:\n",
    "    \n",
    "    bicimad_est = bicimad[bicimad['ESTACION'].isin(cluster)]\n",
    "    \n",
    "    train, test = train_test_split(bicimad_est, test_size = 0.30, random_state = seed)    \n",
    "    X_train = train.drop(['DEMANDA','ESTACION'], axis=1)\n",
    "    X_test = test.drop(['DEMANDA','ESTACION'], axis=1)\n",
    "    y_train = train['DEMANDA']\n",
    "    y_test = test['DEMANDA']\n",
    "    \n",
    "    print(f'Cluster: {iPos}')\n",
    "    print('Estaciones: '+str(len(cluster)))\n",
    "    print('Columnas: '+str(len(bicimad_est.columns)))\n",
    "    iPos=iPos+1\n",
    "    \n",
    "    # Create a based model\n",
    "    rf = RandomForestRegressor(random_state=seed)\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid_RF, cv = 2, n_jobs = -1, verbose = 2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    bestParams = grid_search.best_params_\n",
    "    paramRF.append(bestParams)\n",
    "    print(bestParams)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "203a318a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bootstrap': True,\n",
       "  'max_depth': 80,\n",
       "  'max_features': 7,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 8,\n",
       "  'n_estimators': 1000},\n",
       " {'bootstrap': True,\n",
       "  'max_depth': 80,\n",
       "  'max_features': 7,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 8,\n",
       "  'n_estimators': 1000},\n",
       " {'bootstrap': True,\n",
       "  'max_depth': 80,\n",
       "  'max_features': 7,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 8,\n",
       "  'n_estimators': 1000},\n",
       " {'bootstrap': True,\n",
       "  'max_depth': 80,\n",
       "  'max_features': 7,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 8,\n",
       "  'n_estimators': 1000},\n",
       " {'bootstrap': True,\n",
       "  'max_depth': 80,\n",
       "  'max_features': 7,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 8,\n",
       "  'n_estimators': 1000}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94947f",
   "metadata": {},
   "source": [
    "## Tuneado modelo Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a01462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      "Estaciones: 13\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n",
      "{'learning_rate': 0.01, 'max_depth': 80, 'n_estimators': 500, 'subsample': 0.2}\n",
      "\n",
      "Cluster: 1\n",
      "Estaciones: 28\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n",
      "{'learning_rate': 0.01, 'max_depth': 80, 'n_estimators': 500, 'subsample': 0.1}\n",
      "\n",
      "Cluster: 2\n",
      "Estaciones: 50\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "9 fits failed out of a total of 768.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 586, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 663, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 246, in _fit_stage\n",
      "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 420, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 131, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 227, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 724, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 695, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 3670016 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 586, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 663, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 246, in _fit_stage\n",
      "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 420, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 131, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 227, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 724, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 695, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 1835008 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 586, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 663, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 246, in _fit_stage\n",
      "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 420, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 131, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 227, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 724, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 695, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 917504 bytes\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.50067254 0.51401282 0.49803374 0.47398758 0.53324126 0.57288153\n",
      " 0.5907637  0.59219054 0.53208668 0.5673014  0.57836701 0.5859451\n",
      " 0.53205463 0.56665178 0.57017109 0.57737553 0.50067254 0.51401282\n",
      " 0.49803374 0.47398758 0.53324126 0.57274999 0.59076551 0.59219054\n",
      " 0.53209311 0.56712222 0.57834215 0.5859451  0.53205715 0.56649442\n",
      " 0.5702201  0.57737553 0.50067254 0.51401282 0.49803374 0.47398758\n",
      " 0.53324126 0.5727884  0.59076551 0.59219054 0.53209311 0.56719163\n",
      " 0.57834215 0.5859451  0.53205867 0.56658188 0.57017425 0.57737553\n",
      " 0.50067254 0.51401282 0.49803374 0.47398758 0.53324126 0.57278306\n",
      " 0.59076551 0.59219054 0.53209311 0.56708556 0.57834215 0.5859451\n",
      "        nan        nan 0.57017425 0.57737553 0.54209463 0.57524265\n",
      " 0.57428573 0.55824535        nan 0.56481595        nan 0.57568776\n",
      " 0.53087678 0.56394067 0.55961883 0.55884808 0.53084827 0.56387931\n",
      " 0.55522913 0.54784573 0.54209463 0.57524265 0.57428573 0.55824535\n",
      " 0.53089832 0.56446325 0.57177295 0.57568776 0.53088589 0.56367745\n",
      " 0.55897677 0.55884808 0.5308607  0.563618   0.55474879 0.54784573\n",
      " 0.54209463 0.57524265 0.57428573 0.55824535 0.53089832 0.5645744\n",
      " 0.57177295 0.57568776 0.53085755 0.56384262 0.55898987 0.55884808\n",
      " 0.53081781 0.56386784 0.55494036 0.54784573 0.54209463 0.57524265\n",
      " 0.57428573 0.55824535 0.53089832 0.5646267  0.57177295 0.57568776\n",
      " 0.5308557  0.56383919 0.55898987 0.55884808 0.53081245 0.56380329\n",
      " 0.55494036 0.54784573 0.53139429 0.56688765 0.57740152 0.56599662\n",
      " 0.52856577 0.55718418 0.54403273 0.52800581 0.52855507 0.55702511\n",
      " 0.53807298 0.50749442 0.52843719 0.55662184 0.53681184 0.49953231\n",
      " 0.53139429 0.56693641 0.57740152 0.56599662 0.52856443 0.55698984\n",
      " 0.54344668 0.52800581 0.52852151 0.55672465 0.53745705 0.50749442\n",
      " 0.52839134 0.55633528 0.53608959 0.49953231 0.53139429 0.56693641\n",
      " 0.57740152 0.56599662 0.52857756 0.55744412 0.54344668 0.52800581\n",
      " 0.52850201 0.55711305 0.53745705 0.50749442 0.5284217  0.55685554\n",
      " 0.53594933 0.49953231 0.53139429 0.56693641 0.57740152 0.56599662\n",
      " 0.52857881 0.55725145 0.54344668 0.52800581 0.52849744 0.55714097\n",
      " 0.53745705 0.50749442 0.52838381 0.55690974 0.53594933 0.49953231\n",
      " 0.52117607 0.53915279 0.50684149 0.46201595 0.52108442 0.53787747\n",
      " 0.48077079 0.35463333 0.52076762 0.5370165  0.47859933 0.33594975\n",
      " 0.52069161 0.53563065 0.47483678 0.33191719 0.52117607 0.53898615\n",
      " 0.50726054 0.46201595 0.52094152 0.53805794 0.48109699 0.35463333\n",
      " 0.52063074 0.53721293 0.47770747 0.33594975 0.52044348 0.53523672\n",
      " 0.47367972 0.33191719 0.52117607 0.53883788 0.50726054 0.46201595\n",
      " 0.52106673 0.53743698 0.48109699 0.35463333 0.52071172 0.53629246\n",
      " 0.47770747 0.33594975 0.52052279 0.53467996 0.47367972 0.33191719\n",
      " 0.52117607 0.53888416 0.50726054 0.46201595 0.52104263 0.53728192\n",
      " 0.48109699 0.35463333 0.52070122 0.53609342 0.47770747 0.33594975\n",
      " 0.52042445 0.5343898  0.47367972 0.33191719]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': 80, 'n_estimators': 500, 'subsample': 0.1}\n",
      "\n",
      "Cluster: 3\n",
      "Estaciones: 30\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n",
      "{'learning_rate': 0.01, 'max_depth': 80, 'n_estimators': 500, 'subsample': 0.1}\n",
      "\n",
      "Cluster: 4\n",
      "Estaciones: 51\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "14 fits failed out of a total of 768.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 586, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 663, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 246, in _fit_stage\n",
      "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 420, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 131, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 227, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 724, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 695, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 3670016 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 586, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 663, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 246, in _fit_stage\n",
      "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 420, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 131, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 227, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 724, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 695, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 1835008 bytes\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.610513   0.62308228 0.61288049 0.59072894 0.66693249 0.7004972\n",
      " 0.71921535 0.72379758 0.66599094 0.69480337 0.70725553 0.71946874\n",
      " 0.66598389 0.69406279 0.69963926 0.71204892 0.610513   0.62308228\n",
      " 0.61288049 0.59072894 0.66693249 0.70053369 0.71923203 0.72379758\n",
      "        nan 0.69486619 0.70739804 0.71943578        nan        nan\n",
      " 0.69988298 0.71197307 0.610513   0.62308228 0.61288049 0.59072894\n",
      "        nan 0.70053099 0.71923203 0.72379758 0.66598059 0.69481352\n",
      " 0.7072861  0.71943578 0.66597744 0.69406252 0.6997154  0.71197307\n",
      " 0.610513   0.62308228 0.61288049 0.59072894 0.66693249 0.70055181\n",
      " 0.71923203 0.72379758        nan 0.69487415 0.70734737 0.71943578\n",
      " 0.66597744 0.69409873 0.69953217 0.71197307 0.67105746 0.70050186\n",
      " 0.70386333 0.69070332 0.6658194  0.69296802 0.7033278  0.71254421\n",
      " 0.66584764 0.69198938 0.69095825 0.69870811 0.6658635  0.69191709\n",
      " 0.68647184 0.68947415 0.67105746 0.70050186 0.70386333 0.69070332\n",
      " 0.66581954 0.69299238 0.70283052 0.71254421        nan 0.69186563\n",
      " 0.69050027 0.69931531        nan        nan 0.68588311 0.68925718\n",
      " 0.67105746 0.70050186 0.70386333 0.69070332        nan        nan\n",
      " 0.7029089  0.71254421 0.66585242 0.69205555 0.69040703 0.69931531\n",
      " 0.66586942 0.6920739  0.68579736 0.68925718 0.67105746 0.70050186\n",
      " 0.70386333 0.69070332 0.66581954 0.69303219 0.7029089  0.71254421\n",
      " 0.66585242 0.69199859 0.69040703 0.69931531 0.66586942 0.69208887\n",
      " 0.68579736 0.68925718 0.66710556 0.69778183 0.71160317 0.70966073\n",
      " 0.66481512 0.68785923 0.68201447 0.68219115 0.66471411 0.68745457\n",
      " 0.67581275 0.66343776 0.66465247 0.68707676 0.67411944 0.65525286\n",
      " 0.66710556 0.69778943 0.71160317 0.70966073 0.66482187 0.68761779\n",
      " 0.68219433 0.68219115 0.66479478 0.68710952 0.67534254 0.66343776\n",
      " 0.66475042 0.68682144 0.67375    0.65525286 0.66710556 0.69778943\n",
      " 0.71160317 0.70966073 0.66482187 0.68756355 0.68204766 0.68219115\n",
      " 0.66479478 0.68698662 0.6752977  0.66343776 0.66475042 0.6867132\n",
      " 0.67359086 0.65525286 0.66710556 0.69778943 0.71160317 0.70966073\n",
      " 0.66482187 0.68756355 0.68233095 0.68219115 0.66479478 0.68698662\n",
      " 0.67546853 0.66343776 0.66475042 0.6867132  0.67373133 0.65525286\n",
      " 0.66089102 0.67929914 0.66451804 0.64461854 0.66035067 0.67670246\n",
      " 0.6392306  0.57216546 0.65974515 0.67317402 0.63535522 0.5523064\n",
      " 0.65921252 0.67023067 0.63154472 0.54447781 0.66089102 0.67923183\n",
      " 0.66545818 0.64461854 0.66039672 0.67660771 0.63967821 0.57216546\n",
      " 0.65969918 0.6742112  0.63469725 0.5523064  0.65926027 0.67125164\n",
      " 0.63070885 0.54447781 0.66089102 0.67922764 0.66545818 0.64461854\n",
      " 0.66040567 0.67637017 0.63965297 0.57216546 0.6595912  0.67335111\n",
      " 0.63490118 0.5523064  0.6591073  0.67056051 0.63143449 0.54447781\n",
      " 0.66089102 0.67922764 0.66545818 0.64461854 0.66040567 0.67637017\n",
      " 0.63965297 0.57216546 0.6595912  0.67335111 0.63490118 0.5523064\n",
      " 0.6591073  0.67056051 0.63143449 0.54447781]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': 80, 'n_estimators': 500, 'subsample': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paramGB=[]\n",
    "iPos = 0\n",
    "for cluster in clusterTotal:\n",
    "    \n",
    "    bicimad_est = bicimad[bicimad['ESTACION'].isin(cluster)]\n",
    "    \n",
    "    train, test = train_test_split(bicimad_est, test_size = 0.30, random_state = seed)    \n",
    "    X_train = train.drop(['DEMANDA','ESTACION'], axis=1)\n",
    "    X_test = test.drop(['DEMANDA','ESTACION'], axis=1)\n",
    "    y_train = train['DEMANDA']\n",
    "    y_test = test['DEMANDA']\n",
    "    \n",
    "    print(f'Cluster: {iPos}')\n",
    "    print('Estaciones: '+str(len(cluster)))\n",
    "    print('Columnas: '+str(len(bicimad_est.columns)))\n",
    "    iPos=iPos+1\n",
    "    \n",
    "    # Create a based model\n",
    "    GB = GradientBoostingRegressor(random_state=seed)\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator = GB, param_grid = param_grid_GB, cv = 3, n_jobs = -1, verbose = 2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    bestParams = grid_search.best_params_\n",
    "    paramGB.append(bestParams)\n",
    "    print(bestParams)\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecdb2a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'learning_rate': 0.01,\n",
       "  'max_depth': 80,\n",
       "  'n_estimators': 500,\n",
       "  'subsample': 0.2},\n",
       " {'learning_rate': 0.01,\n",
       "  'max_depth': 80,\n",
       "  'n_estimators': 500,\n",
       "  'subsample': 0.1},\n",
       " {'learning_rate': 0.01,\n",
       "  'max_depth': 80,\n",
       "  'n_estimators': 500,\n",
       "  'subsample': 0.1},\n",
       " {'learning_rate': 0.01,\n",
       "  'max_depth': 80,\n",
       "  'n_estimators': 500,\n",
       "  'subsample': 0.1},\n",
       " {'learning_rate': 0.01,\n",
       "  'max_depth': 80,\n",
       "  'n_estimators': 500,\n",
       "  'subsample': 0.1}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691f61d",
   "metadata": {},
   "source": [
    "## Tuneado modelo LBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fed4d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      "Estaciones: 13\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 500, 'num_leaves': 16}\n",
      "\n",
      "Cluster: 1\n",
      "Estaciones: 28\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 1000, 'num_leaves': 16}\n",
      "\n",
      "Cluster: 2\n",
      "Estaciones: 50\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 1000, 'num_leaves': 16}\n",
      "\n",
      "Cluster: 3\n",
      "Estaciones: 30\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 1000, 'num_leaves': 16}\n",
      "\n",
      "Cluster: 4\n",
      "Estaciones: 51\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 1000, 'num_leaves': 16}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paramLBGM = []\n",
    "iPos = 0\n",
    "for cluster in clusterTotal:\n",
    "    \n",
    "    bicimad_est = bicimad[bicimad['ESTACION'].isin(cluster)]\n",
    "    \n",
    "    train, test = train_test_split(bicimad_est, test_size = 0.30, random_state = seed)    \n",
    "    X_train = train.drop(['DEMANDA','ESTACION'], axis=1)\n",
    "    X_test = test.drop(['DEMANDA','ESTACION'], axis=1)\n",
    "    y_train = train['DEMANDA']\n",
    "    y_test = test['DEMANDA']\n",
    "    \n",
    "    print(f'Cluster: {iPos}')\n",
    "    print('Estaciones: '+str(len(cluster)))\n",
    "    print('Columnas: '+str(len(bicimad_est.columns)))\n",
    "    iPos=iPos+1\n",
    "    \n",
    "    # Create a based model\n",
    "    LGBM = LGBMRegressor(random_state=seed)\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator = LGBM, param_grid = param_grid_LGBM, cv = 3, n_jobs = -1, verbose = 2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    bestParams = grid_search.best_params_\n",
    "    paramLBGM.append(bestParams)\n",
    "    print(bestParams)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2704ba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'learning_rate': 0.1,\n",
       "  'max_depth': 25,\n",
       "  'n_estimators': 500,\n",
       "  'num_leaves': 16},\n",
       " {'learning_rate': 0.1,\n",
       "  'max_depth': 25,\n",
       "  'n_estimators': 1000,\n",
       "  'num_leaves': 16},\n",
       " {'learning_rate': 0.1,\n",
       "  'max_depth': 25,\n",
       "  'n_estimators': 1000,\n",
       "  'num_leaves': 16},\n",
       " {'learning_rate': 0.1,\n",
       "  'max_depth': 25,\n",
       "  'n_estimators': 1000,\n",
       "  'num_leaves': 16},\n",
       " {'learning_rate': 0.1,\n",
       "  'max_depth': 25,\n",
       "  'n_estimators': 1000,\n",
       "  'num_leaves': 16}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramLBGM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e1f41",
   "metadata": {},
   "source": [
    "## Tuneado XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f98c08b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      "Estaciones: 13\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 2916 candidates, totalling 8748 fits\n",
      "{'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 700, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "\n",
      "Cluster: 1\n",
      "Estaciones: 28\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 2916 candidates, totalling 8748 fits\n",
      "{'gamma': 0, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 1000, 'reg_alpha': 1, 'reg_lambda': 200}\n",
      "\n",
      "Cluster: 2\n",
      "Estaciones: 50\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 2916 candidates, totalling 8748 fits\n",
      "{'gamma': 0, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 1000, 'reg_alpha': 0.1, 'reg_lambda': 200}\n",
      "\n",
      "Cluster: 3\n",
      "Estaciones: 30\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 2916 candidates, totalling 8748 fits\n",
      "{'gamma': 0, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 1000, 'reg_alpha': 1, 'reg_lambda': 200}\n",
      "\n",
      "Cluster: 4\n",
      "Estaciones: 51\n",
      "Columnas: 29\n",
      "Fitting 3 folds for each of 2916 candidates, totalling 8748 fits\n",
      "{'gamma': 0, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 1000, 'reg_alpha': 1, 'reg_lambda': 200}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paramXGB=[]\n",
    "iPos = 0\n",
    "for cluster in clusterTotal:\n",
    "    \n",
    "    bicimad_est = bicimad[bicimad['ESTACION'].isin(cluster)]\n",
    "    \n",
    "    train, test = train_test_split(bicimad_est, test_size = 0.30, random_state = seed)    \n",
    "    X_train = train.drop(['DEMANDA','ESTACION'], axis=1)\n",
    "    X_test = test.drop(['DEMANDA','ESTACION'], axis=1)\n",
    "    y_train = train['DEMANDA']\n",
    "    y_test = test['DEMANDA']\n",
    "    \n",
    "    print(f'Cluster: {iPos}')\n",
    "    print('Estaciones: '+str(len(cluster)))\n",
    "    print('Columnas: '+str(len(bicimad_est.columns)))\n",
    "    iPos=iPos+1\n",
    "    \n",
    "    # Create a based model\n",
    "    XGB = XGBRegressor(random_state=seed)\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator = XGB, param_grid = param_grid_XGB, cv = 3, n_jobs = -1, verbose = 2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    bestParams = grid_search.best_params_\n",
    "    paramXGB.append(bestParams)\n",
    "    print(bestParams)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a33f9068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gamma': 0.1,\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 8,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 700,\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 1},\n",
       " {'gamma': 0,\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 8,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'reg_alpha': 1,\n",
       "  'reg_lambda': 200},\n",
       " {'gamma': 0,\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 8,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'reg_alpha': 0.1,\n",
       "  'reg_lambda': 200},\n",
       " {'gamma': 0,\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 8,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'reg_alpha': 1,\n",
       "  'reg_lambda': 200},\n",
       " {'gamma': 0,\n",
       "  'learning_rate': 0.1,\n",
       "  'max_depth': 8,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 1000,\n",
       "  'reg_alpha': 1,\n",
       "  'reg_lambda': 200}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramXGB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
